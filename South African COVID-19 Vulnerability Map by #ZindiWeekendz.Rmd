---
title: "South African COVID-19 Vulnerability Map by #ZindiWeekendz"
output: html_notebook
---
Can we infer important COVID-19 public health risk factors from outdated data? In many countries census and other survey data may be incomplete or out of date. This challenge is to develop a proof-of-concept for how machine learning can help governments more accurately map COVID-19 risk in 2020 using old data, without requiring a new costly, risky, and time-consuming on-the-ground survey.

The 2011 census gives us valuable information for determining who might be most vulnerable to COVID-19 in South Africa. However, the data is nearly 10 years old, and we expect that some key indicators will have changed in that time. Building an up-to-date map showing where the most vulnerable are located will be a key step in responding to the disease. A mapping effort like this requires bringing together many different inputs and tools. For this competition, weâ€™re starting small. Can we infer important risk factors from more readily available data?

The task is to predict the percentage of households that fall into a particularly vulnerable bracket - large households who must leave their homes to fetch water - using 2011 South African census data. Solving this challenge will show that with machine learning it is possible to use easy-to-measure stats to identify areas most at risk even in years when census data is not collected. [Find more information including leadership board here](https://zindi.africa/hackathons/south-african-covid-19-vulnerability-map) 


Loading libraries needed
```{r}
library(tidyverse)
library(caret)
library(randomForest)
```

Loading data
```{r}
train = read.csv("Train_maskedv2.csv")
test = read.csv("Test_maskedv2.csv")
ss = read.csv("samplesubmissionv2.csv")
head(train)
head(test)
```

Checking the column names and data types of the train set
```{r}
str(train) # 50 variables with most data type as num or int
as.data.frame(colSums(is.na(train))) #No missing data recorded
```

Simple Feature selection and Engineering
```{r}
train = train[-c(30:44)] # Removing the language spoken as its not a risk factor
test = test[-c(29:43)]
#Correlation matrix
M = round(cor(train[-c(1,17,18)]), 2) #The columns 17 and 18 are redundants and 1 is wards
# corrplot(M, type="upper", order="original",
#          col=brewer.pal(n=8, name="RdYlBu"))
cor_var = findCorrelation(x = M,
                cutoff = 0.8,
                names = TRUE,
                verbose = FALSE,
                exact = ncol(M) < 100)
cor_var = sort(cor_var)
cor_var = cor_var[-6] # Correlated variable to be removed from the data. 

train = train%>%
  select(-c(cor_var, 16:18)) #Removing correlated and redundant columns
test = test%>%
  select(-c(cor_var, 15:17))

```

Removing other variables that are not risk factors for COVID-19
```{r}
train = train[-c(1,27)]# Removing ward, race and usage of electricity for lighting
train = train%>%
  mutate(household_size = train$total_individuals/train$total_households)

test = test[-c(1,26)]
test = test%>%
  mutate(household_size = total_individuals/total_households)
```

Spliting train data into training_set and validation_sets
```{r}
library(caTools)
set.seed(123)
split = sample.split(train$target_pct_vunerable, SplitRatio = 0.7)
training_set = subset(train, split == TRUE)
validation_set = subset(train, split == FALSE)
```

Modelling
```{r}
# Random Forest Regression
regressor = randomForest(x = training_set[-3],
                         y = training_set$target_pct_vunerable,
                         ntree = 1000,
                         importance = TRUE)
importance(regressor)
varImpPlot(regressor)

```

```{r}
#Predicting new data
y_pred = predict(regressor, newdata = validation_set[-3])
preds = data.frame(y_pred)

# Score
sqrt( mean( (preds$y_pred- validation_set$target_pct_vunerable)^2 , na.rm = TRUE ) ) # RMSE lower is better

```


```{r}
# Random forest using caret package
library(caret)
control = trainControl(method = "repeatedcv", repeats = 3, search = "grid", number = 10)
model_rf <- train(target_pct_vunerable~., data= training_set, trControl = control, method = "rf", tuneLength = 15)
y_pred = predict(model_rf, newdata = validation_set[-3])
preds = data.frame(y_pred)

# Score
sqrt( mean( (preds$y_pred- validation_set$target_pct_vunerable)^2 , na.rm = TRUE ) ) # RMSE lower is better

``` 

Getting predictions
```{r}
# Get predictions
pred.test <- predict(regressor, test)

# Create submission df

ss$target_pct_vunerable <- pred.test


# Save submission file in csv format
write_csv(ss,"mysubmission.csv")
```

Conclusion
This working produced RSME value of 4.80 on the leaders board



